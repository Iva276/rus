import React, { useState, useRef, useEffect } from "react";

export default function RussianReadAloudDemo() {
  const [russianText, setRussianText] = useState("ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! ĞœĞµĞ½Ñ Ğ·Ğ¾Ğ²ÑƒÑ‚ Ğ˜Ğ²Ğ°. Ğ¡ĞµĞ³Ğ¾Ğ´Ğ½Ñ Ñ Ñ€Ğ°ÑÑĞºĞ°Ğ¶Ñƒ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºÑƒÑ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¾ Ñ‚Ğ¾Ğ¼, ĞºĞ°Ğº ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ½Ğ¾Ğ²Ñ‹Ğµ ÑĞ»Ğ¾Ğ²Ğ°. ĞŸĞ¾Ğ²Ñ‚Ğ¾Ñ€ÑĞ¹ Ğ·Ğ° Ğ¼Ğ½Ğ¾Ğ¹ Ğ¿Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸ÑĞ¼ Ğ¸ ÑÑ‚Ğ°Ñ€Ğ°Ğ¹ÑÑ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ½Ğ¾ÑĞ¸Ñ‚ÑŒ Ñ‡ĞµÑ‚ĞºĞ¾.");
  const [chineseText, setChineseText] = useState("");

  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isPaused, setIsPaused] = useState(false);
  const [isRecognizing, setIsRecognizing] = useState(false);
  const [recognizedText, setRecognizedText] = useState("");
  const [score, setScore] = useState<number | null>(null);
  const [status, setStatus] = useState("");

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const recordedChunksRef = useRef<BlobPart[]>([]);
  const [isRecording, setIsRecording] = useState(false);
  const [recordedUrl, setRecordedUrl] = useState<string | null>(null);

  const recognitionRef = useRef<any>(null);

  useEffect(() => {
    if ("speechSynthesis" in window) {
      const loadVoices = () => {
        window.speechSynthesis.getVoices();
      };
      loadVoices();
      if (window.speechSynthesis.onvoiceschanged !== undefined) {
        window.speechSynthesis.onvoiceschanged = loadVoices;
      }
    }

    const SpeechRecognition: any =
      (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
    if (SpeechRecognition) {
      const r = new SpeechRecognition();
      r.lang = "ru-RU";
      r.interimResults = true;
      r.continuous = true;
      r.onresult = (event: any) => {
        let interim = "";
        let final = "";
        for (let i = event.resultIndex; i < event.results.length; ++i) {
          if (event.results[i].isFinal) final += event.results[i][0].transcript;
          else interim += event.results[i][0].transcript;
        }
        setRecognizedText((prev) => {
          return final || interim || prev;
        });
      };
      r.onerror = (e: any) => {
        console.error("è¯†åˆ«é”™è¯¯", e);
        setStatus("è¯†åˆ«é”™è¯¯: " + e.error);
      };
      r.onend = () => {
        setIsRecognizing(false);
        setStatus("è¯†åˆ«ç»“æŸ");
      };
      recognitionRef.current = r;
    }
    return () => {
      if (recognitionRef.current) recognitionRef.current.abort();
    };
  }, []);

  const handleSpeak = () => {
    if (!("speechSynthesis" in window)) {
      alert("æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³åˆæˆ");
      return;
    }

    const synth = window.speechSynthesis;

    if (isPaused) {
      synth.resume();
      setIsPaused(false);
      setStatus("ç»§ç»­æ’­æ”¾...");
      return;
    }

    if (isSpeaking) {
      synth.pause();
      setIsPaused(true);
      setStatus("å·²æš‚åœ");
      return;
    }

    synth.cancel();

    const speak = () => {
      const utterance = new SpeechSynthesisUtterance(russianText);
      utterance.lang = "ru-RU";
      utterance.rate = 0.85;
      utterance.pitch = 1;
      utterance.volume = 1;

      const voices = synth.getVoices();
      console.log("å¯ç”¨è¯­éŸ³:", voices.map(v => `${v.name} (${v.lang})`));

      const russianVoice = voices.find(v =>
        v.lang.includes('ru') || v.lang.includes('RU')
      );

      if (russianVoice) {
        utterance.voice = russianVoice;
        setStatus(`ä½¿ç”¨è¯­éŸ³: ${russianVoice.name}`);
      } else {
        setStatus("æœªæ‰¾åˆ°ä¿„è¯­è¯­éŸ³ï¼Œä½¿ç”¨é»˜è®¤è¯­éŸ³");
      }

      utterance.onstart = () => {
        setIsSpeaking(true);
        setIsPaused(false);
        setStatus("æ­£åœ¨æ’­æ”¾...");
      };

      utterance.onend = () => {
        setIsSpeaking(false);
        setIsPaused(false);
        setStatus("æ’­æ”¾å®Œæˆ");
      };

      utterance.onerror = (e) => {
        setIsSpeaking(false);
        setIsPaused(false);
        setStatus(`é”™è¯¯: ${e.error}`);
        console.error("TTS é”™è¯¯:", e);

        if (e.error === "not-allowed") {
          alert("è¯·å…è®¸æµè§ˆå™¨ä½¿ç”¨è¯­éŸ³åŠŸèƒ½");
        } else if (e.error === "network") {
          alert("ç½‘ç»œé”™è¯¯ï¼Œè¯·æ£€æŸ¥è¿æ¥");
        }
      };

      synth.speak(utterance);
    };

    if (synth.getVoices().length === 0) {
      synth.addEventListener('voiceschanged', speak, { once: true });
    } else {
      speak();
    }
  };

  const handleStop = () => {
    if ("speechSynthesis" in window) {
      window.speechSynthesis.cancel();
      setIsSpeaking(false);
      setIsPaused(false);
      setStatus("å·²åœæ­¢");
    }
  };

  const handleStartRecognition = async () => {
    if (!recognitionRef.current) {
      alert("æµè§ˆå™¨ä¸æ”¯æŒ SpeechRecognition");
      return;
    }
    setRecognizedText("");
    setScore(null);
    setStatus("å¼€å§‹è¯†åˆ«...");
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const recorder = new MediaRecorder(stream);
      recordedChunksRef.current = [];
      recorder.ondataavailable = (e) => {
        if (e.data.size > 0) recordedChunksRef.current.push(e.data);
      };
      recorder.onstop = () => {
        const blob = new Blob(recordedChunksRef.current, { type: "audio/webm" });
        const url = URL.createObjectURL(blob);
        setRecordedUrl(url);
        stream.getTracks().forEach((t) => t.stop());
      };
      recorder.start();
      mediaRecorderRef.current = recorder;
      setIsRecording(true);

      recognitionRef.current.start();
      setIsRecognizing(true);
    } catch (err) {
      console.error(err);
      alert("æ— æ³•è·å–éº¦å…‹é£æˆ–å¯åŠ¨è¯†åˆ«");
    }
  };

  const handleStopRecognition = () => {
    if (recognitionRef.current) recognitionRef.current.stop();
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
    }
    setIsRecognizing(false);
    computeScore();
  };

  const computeScore = () => {
    const original = russianText.toLowerCase().replace(/[^\u0400-\u04FF\s]/g, "");
    const recognized = recognizedText.toLowerCase().replace(/[^\u0400-\u04FF\s]/g, "");
    const origWords = original.split(/\s+/).filter(Boolean);
    const recWords = recognized.split(/\s+/).filter(Boolean);
    if (origWords.length === 0) {
      setScore(0);
      return;
    }
    let matched = 0;
    recWords.forEach((w) => {
      if (origWords.includes(w)) matched++;
    });
    const s = Math.round((matched / origWords.length) * 100);
    setScore(s);
    setStatus(`è¯åŒ¹é…ç‡: ${matched}/${origWords.length}`);
  };

  const handleDownload = () => {
    if (!recordedUrl) return;
    const a = document.createElement("a");
    a.href = recordedUrl;
    a.download = "recording.webm";
    a.click();
  };

  const handleUpload = async () => {
    if (!recordedUrl) return;
    const blob = await fetch(recordedUrl).then((r) => r.blob());
    const formData = new FormData();
    formData.append("audio", blob, "recording.webm");
    formData.append("text", russianText);
    try {
      const res = await fetch("/api/score", { method: "POST", body: formData });
      const data = await res.json();
      alert("ä¸Šä¼ æˆåŠŸï¼ŒæœåŠ¡å™¨è¿”å›: " + JSON.stringify(data));
    } catch (err) {
      console.error(err);
      alert("ä¸Šä¼ å¤±è´¥");
    }
  };

  const handleFileUpload = (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (!file) return;

    const reader = new FileReader();
    reader.onload = (e) => {
      const content = e.target?.result as string;
      setRussianText(content);
      setStatus(`å·²åŠ è½½æ–‡ä»¶: ${file.name}`);
    };
    reader.readAsText(file);
  };

  return (
    <div style={{ maxWidth: 800, margin: "40px auto", padding: 20, fontFamily: "sans-serif" }}>
      <h1>ä¿„è¯­æœ—è¯»ç»ƒä¹ </h1>

      <div style={{ marginBottom: 20 }}>
        <div style={{ marginBottom: 10 }}>
          <label style={{ fontSize: 16, fontWeight: "bold", display: "block", marginBottom: 5 }}>
            ä¿„è¯­æ–‡æœ¬:
          </label>
          <textarea
            value={russianText}
            onChange={(e) => setRussianText(e.target.value)}
            placeholder="åœ¨æ­¤ç²˜è´´æˆ–è¾“å…¥ä¿„è¯­æ–‡æœ¬..."
            style={{
              width: "100%",
              minHeight: 120,
              padding: 10,
              fontSize: 16,
              border: "2px solid #ddd",
              borderRadius: 6,
              fontFamily: "monospace",
              resize: "vertical",
            }}
          />
        </div>

        <div style={{ marginBottom: 10 }}>
          <label style={{ fontSize: 14, display: "block", marginBottom: 5 }}>
            æˆ–ä¸Šä¼ æ–‡æœ¬æ–‡ä»¶ (.txt):
          </label>
          <input
            type="file"
            accept=".txt"
            onChange={handleFileUpload}
            style={{ fontSize: 14 }}
          />
        </div>

        <div style={{ fontSize: 12, color: "#666" }}>
          å­—ç¬¦æ•°: {russianText.length}
        </div>
      </div>

      <div style={{ marginBottom: 20 }}>
        <button onClick={handleSpeak} style={btnStyle}>
          {isPaused ? "â–¶ï¸ ç»§ç»­" : isSpeaking ? "â¸ï¸ æš‚åœ" : "ğŸ”Š æ’­æ”¾"}
        </button>
        {(isSpeaking || isPaused) && (
          <button
            onClick={handleStop}
            style={{ ...btnStyle, background: "#e74c3c", marginLeft: 10 }}
          >
            â¹ï¸ åœæ­¢
          </button>
        )}
        <button
          onClick={() => {
            const voices = window.speechSynthesis.getVoices();
            const info = voices.map(v => `${v.name} (${v.lang})`).join('\n');
            alert(`å…± ${voices.length} ä¸ªè¯­éŸ³:\n\n${info || 'æ— å¯ç”¨è¯­éŸ³'}`);
          }}
          style={{ ...btnStyle, background: "#95a5a6", marginLeft: 10 }}
        >
          æ£€æŸ¥è¯­éŸ³
        </button>
      </div>

      <div style={{ marginBottom: 20 }}>
        {!isRecognizing ? (
          <button onClick={handleStartRecognition} style={btnStyle}>
            å¼€å§‹è·Ÿè¯» + å½•éŸ³
          </button>
        ) : (
          <button onClick={handleStopRecognition} style={{ ...btnStyle, background: "#e74c3c" }}>
            åœæ­¢è·Ÿè¯»
          </button>
        )}
      </div>

      {status && (
        <p style={{ color: "#555", fontSize: 14 }}>
          <strong>çŠ¶æ€:</strong> {status}
        </p>
      )}

      {recognizedText && (
        <div style={{ marginBottom: 20, padding: 15, background: "#f0f0f0", borderRadius: 6 }}>
          <strong>å®æ—¶è¯†åˆ«:</strong>
          <p style={{ margin: "10px 0 0 0" }}>{recognizedText}</p>
        </div>
      )}

      {score !== null && (
        <div style={{ marginBottom: 20, padding: 15, background: "#d4edda", borderRadius: 6 }}>
          <strong>æœ¬åœ°è¯„åˆ†:</strong> {score} åˆ†
        </div>
      )}

      {recordedUrl && (
        <div style={{ marginBottom: 20 }}>
          <p>
            <strong>ä½ çš„å½•éŸ³:</strong>
          </p>
          <audio src={recordedUrl} controls style={{ width: "100%", marginBottom: 10 }} />
          <button onClick={handleDownload} style={{ ...btnStyle, marginRight: 10 }}>
            ä¸‹è½½å½•éŸ³
          </button>
          <button onClick={handleUpload} style={btnStyle}>
            ä¸Šä¼ åˆ°æœåŠ¡å™¨ (ç¤ºä¾‹)
          </button>
        </div>
      )}
    </div>
  );
}

const btnStyle: React.CSSProperties = {
  padding: "10px 20px",
  fontSize: 16,
  background: "#3498db",
  color: "#fff",
  border: "none",
  borderRadius: 6,
  cursor: "pointer",
};
